{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Coursework Part 1: SVMs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports and Data\n",
    "\n",
    "We will be working with the breast cancer dataset as in the slides.\n",
    "\n",
    "I have included the minimal sufficient imports to complete the coursework. You are welcome to import other modules.\n",
    "\n",
    "Sensible comments/observations on any figures/answers will receive credit as in the formative assessments. It is better\n",
    "to comment why you think your results may be wrong than to just leave a wrong figure!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "data=load_breast_cancer()\n",
    "X=data.data\n",
    "y=data.target\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y, stratify=y)\n",
    "X_test+=np.random.rand(*X_test.shape)/20\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Linear SVM for classification\n",
    "### a) For different values of C, use SVC(kernel='linear') and compare the train and test performance of your classifier\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b) For each C compare the number of support vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c) For an optimal value of C, compare the performance of the support vector classifier to Logistic regression/Nearest Centroid for different sized subsets of the training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### d) For difference values of nu, compare the train and test error as well as the number of support vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Kernel Support Vector Machines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a) For different values of degree (and default values of C) compare the performance of a support vector classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b) For the optimal degree polynomial kernel, compare the performance of the polynomial and linear svm classifiers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Distribution of Errors (similar to lecture slides!)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a) Using s=[342, 273, 205, 137, 68, 34, 27, 20] and taking 100 random samples of size s without replacement from the training data compare the distribution of errors or accuracy for the 'nearest centroid' classifier and a linear SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
